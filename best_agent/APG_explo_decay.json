{"agent": "dqn", "states": {"type": "float", "shape": [4, 4, 16], "min_value": 0.0, "max_value": 1.0}, "actions": {"type": "int", "shape": [], "num_values": 4}, "memory": 10000, "batch_size": 16, "max_episode_timesteps": null, "network": "auto", "update_frequency": 4, "start_updating": null, "learning_rate": 0.0001, "huber_loss": null, "horizon": 1, "discount": 0.99, "predict_terminal_values": false, "target_update_weight": 1.0, "target_sync_frequency": 4, "state_preprocessing": "linear_normalization", "reward_preprocessing": null, "exploration": {"type": "exponential", "unit": "episodes", "num_steps": 10000, "initial_value": 0.07, "decay_rate": 0.0001}, "variable_noise": 0.0, "l2_regularization": 0.0, "entropy_regularization": 0.0, "parallel_interactions": 1, "config": null, "saver": null, "summarizer": {"directory": "training_logs/APG_explo_decay/TensorBoard", "summaries": ["episode-reward"]}, "recorder": null, "internals": {}, "initial_internals": {"policy": {}, "baseline": {}}}