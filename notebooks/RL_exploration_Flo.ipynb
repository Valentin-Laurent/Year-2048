{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b02fbe",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ae1a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T15:14:47.352091Z",
     "start_time": "2021-05-25T15:14:47.347239Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_2048\n",
    "import numpy as np\n",
    "from tensorforce import Environment, Agent\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c5816",
   "metadata": {},
   "source": [
    "# First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc049c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T15:24:31.995893Z",
     "start_time": "2021-05-25T15:24:31.989488Z"
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment.create(\n",
    "    environment='gym', level='2048-v0', max_episode_timesteps=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65646e67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T15:24:32.535064Z",
     "start_time": "2021-05-25T15:24:32.409928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(environment._environment.environment.render(mode=\"rgb_array\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98813aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T15:24:51.373808Z",
     "start_time": "2021-05-25T15:24:33.016384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 4.0\n",
      "2 4.0\n",
      "3 4.0\n",
      "4 4.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-30264fb75dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Episode timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorforce/agents/agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, evaluation)\u001b[0m\n\u001b[1;32m    394\u001b[0m             )\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         return super().act(\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindependent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindependent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorforce/agents/recorder.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, states, internals, parallel, independent, deterministic, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# fn_act()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             actions, internals = self.fn_act(\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindependent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindependent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_internals_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_internals_none\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorforce/agents/agent.py\u001b[0m in \u001b[0;36mfn_act\u001b[0;34m(self, states, internals, parallel, independent, deterministic, is_internals_none, num_parallel)\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecover_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Agent.act internals'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             )\n\u001b[0;32m--> 429\u001b[0;31m         auxiliaries = self.auxiliaries_spec.to_tensor(\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauxiliaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Agent.act auxiliaries'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorforce/core/utils/tensors_spec.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(self, value, batched, recover_empty, name)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 )\n\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 tensor[name] = spec.to_tensor(\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecover_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecover_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 )\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorforce/core/utils/tensors_spec.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(self, value, batched, recover_empty, name)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 )\n\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 tensor[name] = spec.to_tensor(\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecover_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecover_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate a Tensorforce agent\n",
    "agent = Agent.create(\n",
    "    agent='dqn',\n",
    "    batch_size= 16,\n",
    "    environment=environment,  # alternatively: state, action, (max_episode_timesteps)\n",
    "    memory=100000,\n",
    "    exploration=0.2,\n",
    "    target_sync_frequency=10,\n",
    "    learning_rate=0.0001,\n",
    "    summarizer=dict(directory='summaries')\n",
    ")\n",
    "\n",
    "# Train for 300 episodes\n",
    "for _ in range(100):\n",
    "\n",
    "    # Initialize episode\n",
    "    state = environment.reset()\n",
    "    terminal = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not terminal:\n",
    "        # Episode timestep\n",
    "        action = agent.act(states=state)\n",
    "        state, terminal, reward = environment.execute(actions=action)\n",
    "        agent.observe(terminal=terminal, reward=reward)\n",
    "        total_reward =+ reward\n",
    "    print(_, total_reward)\n",
    "\n",
    "#agent.close()\n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb843ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
