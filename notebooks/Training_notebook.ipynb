{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b184a774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:22:42.227452Z",
     "start_time": "2021-05-25T13:22:42.222872Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c400da7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:35:04.216008Z",
     "start_time": "2021-05-29T20:35:04.206995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gym_2048\n",
    "from tensorforce import Agent, Environment\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f834cc8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plotting utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f9f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:30:53.896392Z",
     "start_time": "2021-05-29T20:30:53.891175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fonction pour ranger en ordre croissant un dico dans le but de le plotter avec plt\n",
    "def sort_dico(dico):\n",
    "    dico_sorted={}\n",
    "    for k,v in dict(sorted(dico.items())).items():\n",
    "        k_str = str(k)\n",
    "        dico_sorted[k_str] = v\n",
    "\n",
    "    return dico_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a065b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:30:54.923166Z",
     "start_time": "2021-05-29T20:30:54.915511Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fonction pour plotter la distribution des scores et des max tiles\n",
    "# Ã  utiliser avec la fonction de test 'test_agent' et ce qu'elle retourne\n",
    "# dico_sorted = sort_dico(dico_max_tiles_distribution)\n",
    "# rewards = liste_score\n",
    "\n",
    "def plot_metrics(dico_sorted,rewards):\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Max tile distribution')\n",
    "    plt.bar(*zip(*dico_sorted.items()))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Score distribution')\n",
    "    sns.histplot(rewards, kde=True)\n",
    "\n",
    "    print(f'Mean score over the test: {np.mean(rewards)}')\n",
    "    print(f'Median score over the test: {np.median(rewards)}')\n",
    "    print(f'Std score over the test: {np.std(rewards)}')\n",
    "    print(f'Max tile over the test: {max([int(bins) for bins in dico_sorted.keys()])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7ad4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:23:07.931146Z",
     "start_time": "2021-05-25T13:23:07.926389Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Useful code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83046448",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Render \"beautiful\" 2048 grid:\n",
    "\n",
    "`plt.imshow(environment._environment.environment.render(mode=\"rgb_array\"))`\n",
    "\n",
    "Illegal move reward:\n",
    "\n",
    "`environment._environment.environment.set_illegal_move_reward(-10)`\n",
    "\n",
    "Log2 reward:\n",
    "\n",
    "`log2_reward = reward if reward <= 0 else np.log2(reward)`\n",
    "\n",
    "Show TensorBoard graphs:\n",
    "\n",
    "`%tensorboard --logdir summaries` (with parameter `summarizer=dict(directory='summaries')` in the `Agent.create()` method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e12eea",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14278ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:30:58.536107Z",
     "start_time": "2021-05-29T20:30:58.529989Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_agent_and_env(env_params, agent_params):\n",
    "    agent_name = agent_params[\"agent_name\"]\n",
    "    agent_params_ = dict(agent_params)\n",
    "    del agent_params_[\"agent_name\"] # A TensorForce agent doesn't take name as a parameter\n",
    "    \n",
    "    \n",
    "    # create a 2048 environment\n",
    "    environment = Environment.create(\n",
    "        environment = 'gym'\n",
    "        , level = '2048-v0'\n",
    "    )\n",
    "\n",
    "    # create an agent\n",
    "    agent = Agent.create(\n",
    "        agent = 'dqn',\n",
    "        environment = environment,\n",
    "        **agent_params_,\n",
    "        summarizer = dict(directory=f'training_logs/{agent_params[\"agent_name\"]}/TensorBoard',\n",
    "                          summaries=[\"episode-reward\"])\n",
    "    )\n",
    "    return (environment, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ac30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:31:01.355244Z",
     "start_time": "2021-05-29T20:31:01.332717Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_agent(environment, agent, num_episodes, print_freq, agent_name, training_round = 0):\n",
    "\n",
    "    # instantiate lists to record global training metrics\n",
    "    max_tiles = []\n",
    "    scores = []\n",
    "    updates = []\n",
    "    valid_moves = []\n",
    "    run_time = []\n",
    "    start_training_time = time.time()\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = environment.reset()\n",
    "        terminal = False\n",
    "\n",
    "        #Checking metrics while training\n",
    "        state_freeze = state.copy()\n",
    "        num_updates = 0\n",
    "        num_moves = 0\n",
    "        invalid_moves = 0\n",
    "        start_episode_time = time.time()\n",
    "\n",
    "        while not terminal:\n",
    "            #Core\n",
    "            action = agent.act(states=dict(state=state,  action_mask=environment._environment.environment.get_invalid_moves()))\n",
    "            state, terminal, reward = environment.execute(actions=action)\n",
    "            log2_reward = reward if reward <= 0 else np.log2(reward)\n",
    "            num_updates += agent.observe(terminal=terminal, reward=log2_reward)\n",
    "\n",
    "            #Number of moves\n",
    "            num_moves += 1\n",
    "\n",
    "            #Number of invalid moves\n",
    "            if (state == state_freeze).all():\n",
    "                invalid_moves += 1\n",
    "            state_freeze = state.copy()\n",
    "\n",
    "        # Storing score and max tile\n",
    "        max_tiles.append(environment._environment.environment.Matrix.max())\n",
    "        scores.append(environment._environment.environment.score)\n",
    "        updates.append(num_updates)\n",
    "        valid_moves.append(num_moves)\n",
    "        run_time.append(round(time.time() - start_episode_time,2))\n",
    "\n",
    "        if episode % print_freq == 0:\n",
    "            print('Episode {}: score = {}, terminal = {}, updates={}, max_tile={}, valid_moves={}, invalid_moves={}, seconds={}'\\\n",
    "                  .format(episode, environment._environment.environment.score , terminal, num_updates, max_tiles[-1], num_moves-invalid_moves, invalid_moves, round(time.time() - start_episode_time,2)))\n",
    "    \n",
    "    # Saving agent\n",
    "    agent.save(f'training_logs/{agent_name}/agent_round{training_round}', filename=agent_name)\n",
    "    \n",
    "    # Saving metrics\n",
    "    metrics_dict = {\n",
    "        'max_tiles': max_tiles\n",
    "        , 'scores': scores\n",
    "        , 'updates': updates\n",
    "        , 'valid_moves': valid_moves\n",
    "        , 'run_time' : run_time\n",
    "    }\n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "    metrics_path = f'training_logs/{agent_name}/metrics_round{training_round}_({episode}episodes).csv'\n",
    "    metrics_df.to_csv(metrics_path)\n",
    "    \n",
    "    return (metrics_df, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ede69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:31:03.288568Z",
     "start_time": "2021-05-29T20:31:03.281734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_params(agent_params, env_params):\n",
    "    all_params = {\n",
    "        \"agent_params\": agent_params,\n",
    "        \"env_params\": env_params,\n",
    "    }\n",
    "    \n",
    "    directory_path = f'training_logs/{agent_params[\"agent_name\"]}'\n",
    "    !mkdir -p $directory_path\n",
    "    \n",
    "    file_name = f'training_logs/{agent_params[\"agent_name\"]}/params.json'\n",
    "    with open(file_name, 'w') as fp:\n",
    "            json.dump(all_params, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0255aac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49dd500",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`exploration = dict(\n",
    "    type = 'exponential',\n",
    "    unit ='episodes',\n",
    "    num_steps = 10000,\n",
    "    initial_value = 0.2,\n",
    "    decay_rate = 0.0005\n",
    ")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38790d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:31:15.624925Z",
     "start_time": "2021-05-29T20:31:08.707066Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "agent_params = {\n",
    "    \"agent_name\": input(\"Agent name (only letter, digits and underscores). NO SPACE: \"),\n",
    "    'batch_size': 16,\n",
    "    'update_frequency': 4,\n",
    "    'learning_rate': 0.0001,\n",
    "    'discount': 0.99,\n",
    "    'memory': 10000,\n",
    "    'exploration': 0.05,\n",
    "    'target_sync_frequency': 4,\n",
    "    'horizon': 1\n",
    "}\n",
    "\n",
    "env_params = {\n",
    "    'max_episode_timesteps': 10000\n",
    "}\n",
    "\n",
    "if \" \" in agent_params[\"agent_name\"]:\n",
    "    print (\"NO SPACE\")\n",
    "    agent_params = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5eeda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:31:19.802617Z",
     "start_time": "2021-05-29T20:31:19.661149Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Saving params to .json in training_logs folder\n",
    "save_params(agent_params, env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc554896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:31:21.652669Z",
     "start_time": "2021-05-29T20:31:21.183870Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating agent and environnement\n",
    "environment, agent = create_agent_and_env(env_params, agent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70628737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:33:33.704260Z",
     "start_time": "2021-05-29T20:31:32.552431Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train ! Increment training round for several round of trainings\n",
    "\n",
    "training_params = {\n",
    "    \"num_episodes\": 100,\n",
    "    \"print_freq\": 10,\n",
    "    \"agent_name\": agent_params[\"agent_name\"],\n",
    "    \"training_round\": 0\n",
    "}\n",
    "\n",
    "metrics_df, agent = train_agent(environment, agent, **training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1625aa1",
   "metadata": {},
   "source": [
    "# Plotting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd72bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T21:40:18.775110Z",
     "start_time": "2021-05-29T21:40:18.761807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading from CSV, but works also with the metrics_df variable created above\n",
    "df1 = pd.read_csv(\"training_logs/yoyoyo/metrics_round0_(99episodes).csv\")\n",
    "scores1 = df1[\"scores\"]\n",
    "df2 = pd.read_csv(\"training_logs/agent_2/metrics0.csv\")\n",
    "scores2 = df2[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302af1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T21:42:37.570209Z",
     "start_time": "2021-05-29T21:42:37.305215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Raw training data\n",
    "sns.lineplot(data=scores1, label = \"agent_1\");\n",
    "sns.lineplot(data=scores2, label = \"agent_2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39065a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T21:51:47.900864Z",
     "start_time": "2021-05-29T21:51:47.657761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Smoothed curves (moving average on N points)\n",
    "N = 5\n",
    "print(\"Training time agent_1:\", round(df1[\"run_time\"].sum()/60), \"minutes\")\n",
    "print(\"Training time agent_2:\", round(df2[\"run_time\"].sum()/60), \"minutes\")\n",
    "plt.figure().suptitle(f\"Moving average on {N} points\")\n",
    "sns.lineplot(data = uniform_filter1d(scores1, size=N, mode = \"reflect\"), label = \"Score agent_1\");\n",
    "sns.lineplot(data = uniform_filter1d(scores2, size=N, mode = \"reflect\"), label = \"Score agent_2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc7b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:55:10.942248Z",
     "start_time": "2021-05-28T12:49:31.721Z"
    }
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"training_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294eb62",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424ccf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:55:10.950315Z",
     "start_time": "2021-05-28T12:49:31.724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate for n episodes\n",
    "def test_agent(agent,n_episode):\n",
    "    #definir l'env\n",
    "    environment = Environment.create(environment = 'gym', level = '2048-v0', \n",
    "    max_episode_timesteps = 1000\n",
    "    )\n",
    "    n_episode = n_episode\n",
    "    #dictionnaire pour obtenir la distribution des max tiles de chaque episode\n",
    "    dico_max_tiles_distribution = {}\n",
    "    # liste des score par episode\n",
    "    liste_score=[]\n",
    "    # dictionnaire pour rÃ©cupÃ©rer la meilleure et la pire partie du test\n",
    "    dico_best_worst_episode = {'Worst':[],'Best':[], 'Episode # Worst':[], 'Episode # Best':[]}\n",
    "\n",
    "    for episode in range(n_episode):\n",
    "        sum_rewards = 0.0\n",
    "        states = environment.reset()\n",
    "        list_states=[]\n",
    "        internals = agent.initial_internals()\n",
    "        terminal = False\n",
    "\n",
    "        while not terminal:\n",
    "            actions, internals = agent.act(\n",
    "                states= {\n",
    "                    \"state\":states,\n",
    "                    \"action_mask\":environment._environment.environment.get_invalid_moves()},\n",
    "                internals=internals,\n",
    "                independent=True, deterministic=True\n",
    "            )\n",
    "            states, terminal, reward = environment.execute(actions=actions)\n",
    "            matrix = environment._environment.environment.Matrix\n",
    "            list_states.append(matrix.copy())\n",
    "            sum_rewards += reward\n",
    "\n",
    "        liste_score.append(sum_rewards)\n",
    "\n",
    "        if sum_rewards >= max(liste_score):\n",
    "            dico_best_worst_episode['Best'] = list_states\n",
    "            dico_best_worst_episode['Episode # Best'] = episode\n",
    "        elif sum_rewards <= min(liste_score):\n",
    "            dico_best_worst_episode['Worst'] = list_states\n",
    "            dico_best_worst_episode['Episode # Worst'] = episode\n",
    "\n",
    "        dico_max_tiles_distribution.setdefault(environment._environment.environment.Matrix.max(),0)\n",
    "        dico_max_tiles_distribution[environment._environment.environment.Matrix.max()] += 1\n",
    "\n",
    "    return dico_best_worst_episode, liste_score, dico_max_tiles_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b77c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:55:10.960793Z",
     "start_time": "2021-05-28T12:49:31.726Z"
    }
   },
   "outputs": [],
   "source": [
    "results = test_agent(agent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29e2d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T12:55:10.964952Z",
     "start_time": "2021-05-28T12:49:31.728Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metrics(sort_dico(results[2]), results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
