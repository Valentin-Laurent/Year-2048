{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b184a774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:22:42.227452Z",
     "start_time": "2021-05-25T13:22:42.222872Z"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776219e",
   "metadata": {},
   "source": [
    "Collab specific stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d453b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:13:58.795288Z",
     "start_time": "2021-05-27T12:13:58.791376Z"
    }
   },
   "outputs": [],
   "source": [
    "running_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d954ca1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:13:59.247352Z",
     "start_time": "2021-05-27T12:13:59.242068Z"
    }
   },
   "outputs": [],
   "source": [
    "if running_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    logs_directory = 'drive/MyDrive/summaries'\n",
    "    !pip install -r \"drive/MyDrive/requirements.txt\"\n",
    "else:\n",
    "    logs_directory = 'summaries'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c5cd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:44:26.531364Z",
     "start_time": "2021-05-26T07:44:25.843849Z"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c400da7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:14:03.305236Z",
     "start_time": "2021-05-27T12:14:00.137556Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gym_2048\n",
    "from tensorforce import Agent, Environment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99978760",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7ad4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:23:07.931146Z",
     "start_time": "2021-05-25T13:23:07.926389Z"
    }
   },
   "source": [
    "# Useful code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83046448",
   "metadata": {},
   "source": [
    "Render \"beautiful\" 2048 grid:\n",
    "\n",
    "`imshow(environment._environment.environment.render(mode=\"rgb_array\"))`\n",
    "\n",
    "Illegal move reward:\n",
    "\n",
    "`environment._environment.environment.set_illegal_move_reward(-10)`\n",
    "\n",
    "Log2 reward:\n",
    "\n",
    "`log2_reward = reward if reward <= 0 else np.log2(reward)`\n",
    "\n",
    "Show TensorBoard graphs:\n",
    "\n",
    "`%tensorboard --logdir summaries` (with parameter `summarizer=dict(directory='summaries')` in the `Agent.create()` method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40679b34",
   "metadata": {},
   "source": [
    "# Hyperparams to test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7694a",
   "metadata": {},
   "source": [
    "`exploration`\n",
    "\n",
    "`learning_rate`\n",
    "\n",
    "Negative reward for illegal moves: `environment._environment.environment.set_illegal_move_reward(-1)`\n",
    "\n",
    "`target_sync_frequency`\n",
    "\n",
    "`batch_size` & `update_frequency`\n",
    "\n",
    "Constant reward / Log reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e12eea",
   "metadata": {},
   "source": [
    "# Custom hyper params train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125ff80",
   "metadata": {},
   "source": [
    "Modified hyperparams :\n",
    "\n",
    "Ex: `learning_rate = 0.01` et `batch_size = 32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0ac30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T12:14:03.555172Z",
     "start_time": "2021-05-27T12:14:03.539997Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "hyperparams_dict = {\n",
    "    'max_episode_timesteps': 1000 # Maximum steps allowed in episode. This hyper-param is for environment\n",
    "    , 'batch_size': 16\n",
    "    , 'update_frequency': 4\n",
    "    , 'learning_rate': 0.001\n",
    "    , 'discount': 0.8\n",
    "    , 'memory': 30000\n",
    "    , 'exploration': 0.1\n",
    "    , 'target_sync_frequency': 4\n",
    "    , 'horizon': 2\n",
    "}\n",
    "\n",
    "def train_agent(params, num_episodes, print_freq, csv_name):\n",
    "    ''' Function creating environment & agent based on params dict. \n",
    "    num_episodes defines how many episodes agent will train & print_freq defines \n",
    "    printing frequency. \n",
    "    Function will create dict of metrics & dict of params used in function & both\n",
    "    will be saved as a csv with csv_name'''\n",
    "\n",
    "    # create a 2048 environment\n",
    "    environment = Environment.create(\n",
    "        environment = 'gym'\n",
    "        , level = '2048-v0'\n",
    "        , max_episode_timesteps = hyperparams_dict['max_episode_timesteps']\n",
    "    )\n",
    "\n",
    "    # create an agent\n",
    "    agent = Agent.create(\n",
    "        agent = 'dqn'\n",
    "        , batch_size = hyperparams_dict['max_episode_timesteps']\n",
    "        , update_frequency = hyperparams_dict['update_frequency']\n",
    "        , environment = environment\n",
    "        , learning_rate = hyperparams_dict['learning_rate']\n",
    "        , discount = hyperparams_dict['discount']\n",
    "        , memory = hyperparams_dict['memory']\n",
    "        , exploration = hyperparams_dict['exploration']\n",
    "        , target_sync_frequency = hyperparams_dict['target_sync_frequency']\n",
    "        , horizon = hyperparams_dict['horizon']\n",
    "        , summarizer = dict(directory=logs_directory\n",
    "                            , summaries=[\n",
    "                                \"regularization-loss\"\n",
    "                                , \"loss\"\n",
    "                                , \"episode-length\"\n",
    "                                , \"episode-reward\"\n",
    "                                , \"objective-loss\"\n",
    "                                , \"reward\"\n",
    "                                , \"update-return\"\n",
    "                            ]\n",
    "                           )\n",
    "    )\n",
    "\n",
    "    # instantiate lists to record global training metrics\n",
    "    max_tiles = []\n",
    "    scores = []\n",
    "    updates = []\n",
    "    valid_moves = []\n",
    "    run_time = []\n",
    "    start_training_time = time.time()\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = environment.reset()\n",
    "        terminal = False\n",
    "\n",
    "        #Checking metrics while training\n",
    "        state_freeze = state.copy()\n",
    "        num_updates = 0\n",
    "        num_moves = 0\n",
    "        invalid_moves = 0\n",
    "        start_episode_time = time.time()\n",
    "\n",
    "        while not terminal:\n",
    "            #Core\n",
    "            action = agent.act(states=dict(state=state,  action_mask=environment._environment.environment.get_invalid_moves()))\n",
    "            state, terminal, reward = environment.execute(actions=action)\n",
    "            log2_reward = reward if reward <= 0 else np.log2(reward)\n",
    "            num_updates += agent.observe(terminal=terminal, reward=log2_reward)\n",
    "\n",
    "            #Number of moves\n",
    "            num_moves += 1\n",
    "\n",
    "            #Number of invalid moves\n",
    "            if (state == state_freeze).all():\n",
    "                invalid_moves += 1\n",
    "            state_freeze = state.copy()\n",
    "\n",
    "        # Storing score and max tile\n",
    "        max_tiles.append(environment._environment.environment.Matrix.max())\n",
    "        scores.append(environment._environment.environment.score)\n",
    "        updates.append(num_updates)\n",
    "        valid_moves.append(num_moves)\n",
    "        run_time.append(round(time.time() - start_episode_time,2))\n",
    "\n",
    "        if episode % print_freq == 0:\n",
    "            print('Episode {}: score = {}, terminal = {}, updates={}, max_tile={}, valid_moves={}, invalid_moves={}, seconds={}'\\\n",
    "                  .format(episode, environment._environment.environment.score , terminal, num_updates, max_tiles[-1], num_moves-invalid_moves, invalid_moves, round(time.time() - start_episode_time,2)))\n",
    "        \n",
    "    metrics_dict = {\n",
    "        'max_tiles': max_tiles\n",
    "        , 'scores': scores\n",
    "        , 'updates': updates\n",
    "        , 'valid_moves': valid_moves\n",
    "        , 'run_time' : run_time\n",
    "    }\n",
    "    \n",
    "    params_dict = params\n",
    "    params_dict['num_episodes'] = num_episodes\n",
    "    \n",
    "    #params_df = pd.DataFrame(params_dict)\n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "    \n",
    "    #params_path = f'training_csv/params_{csv_name}.csv'\n",
    "    metrics_path = f'training_runs/{csv_name}_metrics.csv'\n",
    "    #params_df.to_csv(params_path)\n",
    "    metrics_df.to_csv(metrics_path)\n",
    "    \n",
    "    environment.close()\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70628737",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T12:14:05.778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: score = 660.0, terminal = 1, updates=20, max_tile=64, valid_moves=87, invalid_moves=0, seconds=5.04\n",
      "Episode 100: score = 684.0, terminal = 1, updates=23, max_tile=64, valid_moves=93, invalid_moves=0, seconds=2.22\n",
      "Episode 200: score = 1492.0, terminal = 1, updates=37, max_tile=128, valid_moves=150, invalid_moves=0, seconds=3.57\n",
      "Episode 300: score = 664.0, terminal = 1, updates=22, max_tile=64, valid_moves=91, invalid_moves=0, seconds=1.99\n",
      "Episode 400: score = 864.0, terminal = 1, updates=25, max_tile=64, valid_moves=101, invalid_moves=0, seconds=2.32\n",
      "Episode 500: score = 1148.0, terminal = 1, updates=30, max_tile=128, valid_moves=122, invalid_moves=0, seconds=2.74\n"
     ]
    }
   ],
   "source": [
    "test_df = train_agent(hyperparams_dict, 1000, 100, '1000_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc4dd1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T12:14:06.612Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be743ce1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T12:14:08.701Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(test_df.max_tiles)),test_df.max_tiles, color = 'b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88cc7b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T10:48:33.131459Z",
     "start_time": "2021-05-27T10:48:29.586012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2ce6888326e3cb0a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2ce6888326e3cb0a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $logs_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a497f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T15:26:47.015574Z",
     "start_time": "2021-05-25T15:26:47.007913Z"
    }
   },
   "source": [
    "# Default hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ce4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:53:08.751473Z",
     "start_time": "2021-05-27T09:52:40.120Z"
    }
   },
   "outputs": [],
   "source": [
    "#environment = Environment.create(\n",
    "#    environment='gym', level='2048-v0', max_episode_timesteps=1000\n",
    "#)\n",
    "\n",
    "# Defaut hyperparams\n",
    "#agent = Agent.create(\n",
    "#    agent='dqn',\n",
    "#    batch_size=16, # Required by Tensorforce\n",
    "#    update_frequency=4, # Update frequency, TensorForce default : batch_size * 0.25\n",
    "#    learning_rate = 0.001, # (TensorForce default)\n",
    "#    discount = 0.99, # (TensorForce default)\n",
    "#    memory=10000,\n",
    "#    exploration=0.1, # (0 is the TensorForce default)\n",
    "#    target_sync_frequency=4, # (1 is the TensorForce default)\n",
    "#)\n",
    "#\n",
    "#for episode in range(1000):\n",
    "#    train...\n",
    "#    log2_reward = reward if reward <= 0 else np.log2(reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
