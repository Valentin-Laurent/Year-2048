{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6356a9a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:22:42.227452Z",
     "start_time": "2021-05-25T13:22:42.222872Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c56755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:18:41.745489Z",
     "start_time": "2021-05-26T07:18:41.728950Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gym_2048\n",
    "from tensorforce import Agent, Environment\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65fca",
   "metadata": {},
   "source": [
    "Collab specific stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a13d3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:18:44.003551Z",
     "start_time": "2021-05-26T07:18:43.996883Z"
    }
   },
   "outputs": [],
   "source": [
    "running_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1147f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:18:44.925415Z",
     "start_time": "2021-05-26T07:18:44.919813Z"
    }
   },
   "outputs": [],
   "source": [
    "if running_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    logs_directory = 'drive/MyDrive/summaries'\n",
    "    pip install tensorforce\n",
    "    pip install gym-2048 git+https://github.com/Valentin-Laurent/gym-2048.git\n",
    "    \n",
    "else:\n",
    "    logs_directory = 'summaries'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ce6d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T13:23:07.931146Z",
     "start_time": "2021-05-25T13:23:07.926389Z"
    }
   },
   "source": [
    "# Useful code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac96d1",
   "metadata": {},
   "source": [
    "Render \"beautiful\" 2048 grid:\n",
    "\n",
    "`imshow(environment._environment.environment.render(mode=\"rgb_array\"))`\n",
    "\n",
    "Illegal move reward:\n",
    "\n",
    "`environment._environment.environment.set_illegal_move_reward(-10)`\n",
    "\n",
    "Log2 reward:\n",
    "\n",
    "`log2_reward = reward if reward <= 0 else np.log2(reward)`\n",
    "\n",
    "Show TensorBoard graphs:\n",
    "\n",
    "`%tensorboard --logdir summaries` (with parameter `summarizer=dict(directory='summaries')` in the `Agent.create()` method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9f241e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparams to test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8741df6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`exploration`\n",
    "\n",
    "`learning_rate`\n",
    "\n",
    "Negative reward for illegal moves: `environment._environment.environment.set_illegal_move_reward(-1)`\n",
    "\n",
    "`target_sync_frequency`\n",
    "\n",
    "`batch_size` & `update_frequency`\n",
    "\n",
    "Constant reward / Log reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a136f",
   "metadata": {},
   "source": [
    "# Custom hyper params train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed7d602",
   "metadata": {},
   "source": [
    "Modified hyperparams :\n",
    "\n",
    "Ex: `learning_rate = 0.01` et `batch_size = 32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ac30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:21:46.010244Z",
     "start_time": "2021-05-26T07:21:20.344084Z"
    }
   },
   "outputs": [],
   "source": [
    "environment = Environment.create(\n",
    "    environment='gym', level='2048-v0', max_episode_timesteps=1000\n",
    ")\n",
    "\n",
    "# Defaut hyperparams\n",
    "agent = Agent.create(\n",
    "    agent='dqn',\n",
    "    batch_size=16, # Required by Tensorforce\n",
    "    update_frequency=4, # Update frequency, TensorForce default : batch_size * 0.25\n",
    "    environment=environment,\n",
    "    learning_rate = 0.001, # (TensorForce default)\n",
    "    discount = 0.99, # (TensorForce default)\n",
    "    memory=10000,\n",
    "    exploration=0.1, # (0 is the TensorForce default)\n",
    "    target_sync_frequency=4, # (1 is the TensorForce default)\n",
    "    summarizer=dict(directory=logs_directory)\n",
    ")\n",
    "\n",
    "max_tiles = []\n",
    "scores = []\n",
    "start_training_time = time.time()\n",
    "\n",
    "for episode in range(100):\n",
    "    state = environment.reset()\n",
    "    terminal = False\n",
    "    \n",
    "    #Checking metrics while training\n",
    "    state_freeze = state.copy()\n",
    "    num_updates = 0\n",
    "    num_moves = 0\n",
    "    invalid_moves = 0\n",
    "    start_episode_time = time.time()\n",
    "    \n",
    "    while not terminal:\n",
    "        #Core\n",
    "        action = agent.act(states=state)\n",
    "        state, terminal, reward = environment.execute(actions=action)\n",
    "        log2_reward = reward if reward <= 0 else np.log2(reward)\n",
    "        num_updates += agent.observe(terminal=terminal, reward=log2_reward)\n",
    "\n",
    "        #Number of moves\n",
    "        num_moves += 1\n",
    "        \n",
    "        #Number of invalid moves\n",
    "        if (state == state_freeze).all():\n",
    "            invalid_moves += 1\n",
    "        state_freeze = state.copy()\n",
    "    \n",
    "    # Storing score and max tile\n",
    "    max_tiles.append(environment._environment.environment.Matrix.max())\n",
    "    scores.append(environment._environment.environment.score)\n",
    "    \n",
    "    print('Episode {}: terminal = {}, updates={}, max_tile={}, valid_moves={}, invalid_moves={}, seconds={}'\\\n",
    "          .format(episode, terminal, num_updates, max_tiles[-1], num_moves-invalid_moves, invalid_moves, round(time.time() - start_episode_time,2)))\n",
    "\n",
    "agent.close()\n",
    "environment.close()\n",
    "print(\"Last 100 episodes mean score: \", np.mean(scores[-100:]))\n",
    "print(\"Max tile on last 100 episodes: \", max(max_tiles[-100:]))\n",
    "print(\"Total training time (minutes): \", round((time.time() - start_training_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab378d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:23:39.726572Z",
     "start_time": "2021-05-26T07:23:33.672743Z"
    }
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir $logs_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be93cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T15:26:47.015574Z",
     "start_time": "2021-05-25T15:26:47.007913Z"
    }
   },
   "source": [
    "# Default hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment.create(\n",
    "    environment='gym', level='2048-v0', max_episode_timesteps=1000\n",
    ")\n",
    "\n",
    "# Defaut hyperparams\n",
    "agent = Agent.create(\n",
    "    agent='dqn',\n",
    "    batch_size=16, # Required by Tensorforce\n",
    "    update_frequency=4, # Update frequency, TensorForce default : batch_size * 0.25\n",
    "    learning_rate = 0.001, # (TensorForce default)\n",
    "    discount = 0.99, # (TensorForce default)\n",
    "    memory=10000,\n",
    "    exploration=0.1, # (0 is the TensorForce default)\n",
    "    target_sync_frequency=4, # (1 is the TensorForce default)\n",
    ")\n",
    "\n",
    "for episode in range(1000):\n",
    "    train...\n",
    "    log2_reward = reward if reward <= 0 else np.log2(reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
